{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "logical-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk==3.5\n",
    "# !pip install colorama==0.4.3\n",
    "# !pip install numpy==1.18.5\n",
    "# !pip install scikit_learn==0.23.2\n",
    "# !pip install Flask==1.1.2\n",
    "#https://towardsdatascience.com/how-to-build-your-own-chatbot-using-deep-learning-bb41f970e281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfactory-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-writer",
   "metadata": {},
   "source": [
    "### Loading Json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intent.json') as file:\n",
    " data=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "therapeutic-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'goodbye',\n",
       " 'thanks',\n",
       " 'about',\n",
       " 'name',\n",
       " 'help',\n",
       " 'createaccount',\n",
       " 'complaint']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentences=[]\n",
    "training_labels=[]\n",
    "labels=[]\n",
    "responses=[]\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])     \n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "        \n",
    "num_classes=len(labels)        \n",
    "    \n",
    "    \n",
    "training_sentences   \n",
    "responses\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broke-partnership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 3 3 3 7 7 7 7 0 0 0 6 6 6 5 5 5 5 5 5 5 2 2 2 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "lbl_encoder=LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels=lbl_encoder.transform(training_labels)\n",
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suitable-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "graduate-convergence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 16)            16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 16,680\n",
      "Trainable params: 16,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/#:~:text=The%20output%20of%20the%20Embedding,vector%20using%20the%20Flatten%20layer.\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "settled-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='sequential_model.png', show_shapes=True, show_dtype=False,\n",
    "        show_layer_names=True, rankdir='TB', expand_nested=True, dpi=80 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "golden-swing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 2.0748 - accuracy: 0.1250 - val_loss: 2.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0715 - accuracy: 0.1250 - val_loss: 2.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0682 - accuracy: 0.1250 - val_loss: 2.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0653 - accuracy: 0.1250 - val_loss: 2.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0622 - accuracy: 0.1250 - val_loss: 2.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0593 - accuracy: 0.1250 - val_loss: 2.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0561 - accuracy: 0.1250 - val_loss: 2.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.0533 - accuracy: 0.1250 - val_loss: 2.1254 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.0497 - accuracy: 0.1250 - val_loss: 2.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0475 - accuracy: 0.1250 - val_loss: 2.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0439 - accuracy: 0.1250 - val_loss: 2.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0408 - accuracy: 0.1250 - val_loss: 2.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0373 - accuracy: 0.1667 - val_loss: 2.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.0338 - accuracy: 0.2500 - val_loss: 2.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0308 - accuracy: 0.3333 - val_loss: 2.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0268 - accuracy: 0.3750 - val_loss: 2.1757 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0229 - accuracy: 0.3333 - val_loss: 2.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0197 - accuracy: 0.3333 - val_loss: 2.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0158 - accuracy: 0.3333 - val_loss: 2.1999 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.0120 - accuracy: 0.2083 - val_loss: 2.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.0076 - accuracy: 0.2500 - val_loss: 2.2181 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0032 - accuracy: 0.3333 - val_loss: 2.2278 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9993 - accuracy: 0.3333 - val_loss: 2.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9944 - accuracy: 0.3333 - val_loss: 2.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9905 - accuracy: 0.3333 - val_loss: 2.2598 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9863 - accuracy: 0.2917 - val_loss: 2.2715 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9817 - accuracy: 0.2917 - val_loss: 2.2831 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.9765 - accuracy: 0.2917 - val_loss: 2.2948 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9729 - accuracy: 0.2917 - val_loss: 2.3074 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9673 - accuracy: 0.3333 - val_loss: 2.3200 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.9628 - accuracy: 0.3750 - val_loss: 2.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.9584 - accuracy: 0.3750 - val_loss: 2.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.9536 - accuracy: 0.3750 - val_loss: 2.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.9480 - accuracy: 0.3750 - val_loss: 2.3761 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.9439 - accuracy: 0.3750 - val_loss: 2.3919 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9381 - accuracy: 0.2500 - val_loss: 2.4081 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9331 - accuracy: 0.2500 - val_loss: 2.4248 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.9279 - accuracy: 0.2500 - val_loss: 2.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9230 - accuracy: 0.2500 - val_loss: 2.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.9172 - accuracy: 0.2917 - val_loss: 2.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9132 - accuracy: 0.2917 - val_loss: 2.4965 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9068 - accuracy: 0.2917 - val_loss: 2.5150 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9017 - accuracy: 0.2917 - val_loss: 2.5348 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.8969 - accuracy: 0.2500 - val_loss: 2.5552 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8910 - accuracy: 0.2917 - val_loss: 2.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.8858 - accuracy: 0.4167 - val_loss: 2.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8817 - accuracy: 0.4167 - val_loss: 2.6189 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.8757 - accuracy: 0.4167 - val_loss: 2.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.8710 - accuracy: 0.4583 - val_loss: 2.6655 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.8655 - accuracy: 0.4583 - val_loss: 2.6890 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.8600 - accuracy: 0.4583 - val_loss: 2.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.8556 - accuracy: 0.4583 - val_loss: 2.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8496 - accuracy: 0.4167 - val_loss: 2.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.8455 - accuracy: 0.4167 - val_loss: 2.7848 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.8403 - accuracy: 0.4167 - val_loss: 2.8100 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8354 - accuracy: 0.4167 - val_loss: 2.8353 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 1.8301 - accuracy: 0.4167 - val_loss: 2.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8256 - accuracy: 0.4167 - val_loss: 2.8863 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.8209 - accuracy: 0.4167 - val_loss: 2.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.8169 - accuracy: 0.3750 - val_loss: 2.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8120 - accuracy: 0.3333 - val_loss: 2.9674 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8073 - accuracy: 0.2917 - val_loss: 2.9942 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8024 - accuracy: 0.3333 - val_loss: 3.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7981 - accuracy: 0.3750 - val_loss: 3.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7938 - accuracy: 0.4167 - val_loss: 3.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7904 - accuracy: 0.4167 - val_loss: 3.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7848 - accuracy: 0.4167 - val_loss: 3.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7800 - accuracy: 0.4167 - val_loss: 3.1458 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7758 - accuracy: 0.4583 - val_loss: 3.1649 - val_accuracy: 0.1111\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7725 - accuracy: 0.4583 - val_loss: 3.1840 - val_accuracy: 0.1111\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7673 - accuracy: 0.4583 - val_loss: 3.2057 - val_accuracy: 0.1111\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.7631 - accuracy: 0.4583 - val_loss: 3.2293 - val_accuracy: 0.1111\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7592 - accuracy: 0.4583 - val_loss: 3.2532 - val_accuracy: 0.1111\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7544 - accuracy: 0.4583 - val_loss: 3.2742 - val_accuracy: 0.1111\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7513 - accuracy: 0.4583 - val_loss: 3.2953 - val_accuracy: 0.1111\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7461 - accuracy: 0.4583 - val_loss: 3.3201 - val_accuracy: 0.1111\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7421 - accuracy: 0.4583 - val_loss: 3.3451 - val_accuracy: 0.1111\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7385 - accuracy: 0.4583 - val_loss: 3.3678 - val_accuracy: 0.1111\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7342 - accuracy: 0.4583 - val_loss: 3.3905 - val_accuracy: 0.1111\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7295 - accuracy: 0.4583 - val_loss: 3.4139 - val_accuracy: 0.1111\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7251 - accuracy: 0.4583 - val_loss: 3.4388 - val_accuracy: 0.1111\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7219 - accuracy: 0.4583 - val_loss: 3.4637 - val_accuracy: 0.1111\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.7178 - accuracy: 0.4583 - val_loss: 3.4884 - val_accuracy: 0.1111\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.7125 - accuracy: 0.4583 - val_loss: 3.5138 - val_accuracy: 0.1111\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7088 - accuracy: 0.4583 - val_loss: 3.5395 - val_accuracy: 0.1111\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7047 - accuracy: 0.4583 - val_loss: 3.5665 - val_accuracy: 0.1111\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7003 - accuracy: 0.4583 - val_loss: 3.5923 - val_accuracy: 0.1111\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6962 - accuracy: 0.4583 - val_loss: 3.6189 - val_accuracy: 0.1111\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6919 - accuracy: 0.4583 - val_loss: 3.6466 - val_accuracy: 0.1111\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6879 - accuracy: 0.4583 - val_loss: 3.6734 - val_accuracy: 0.1111\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.6836 - accuracy: 0.4583 - val_loss: 3.6969 - val_accuracy: 0.1111\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6791 - accuracy: 0.4583 - val_loss: 3.7197 - val_accuracy: 0.1111\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.6748 - accuracy: 0.4583 - val_loss: 3.7394 - val_accuracy: 0.1111\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6708 - accuracy: 0.4583 - val_loss: 3.7600 - val_accuracy: 0.1111\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.6661 - accuracy: 0.4583 - val_loss: 3.7822 - val_accuracy: 0.1111\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6618 - accuracy: 0.4583 - val_loss: 3.8026 - val_accuracy: 0.1111\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.6572 - accuracy: 0.4583 - val_loss: 3.8244 - val_accuracy: 0.1111\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.6521 - accuracy: 0.4583 - val_loss: 3.8469 - val_accuracy: 0.1111\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6476 - accuracy: 0.4583 - val_loss: 3.8706 - val_accuracy: 0.1111\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.6426 - accuracy: 0.4583 - val_loss: 3.8965 - val_accuracy: 0.1111\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.6382 - accuracy: 0.4583 - val_loss: 3.9222 - val_accuracy: 0.1111\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.6330 - accuracy: 0.4583 - val_loss: 3.9462 - val_accuracy: 0.1111\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6279 - accuracy: 0.4583 - val_loss: 3.9677 - val_accuracy: 0.1111\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6224 - accuracy: 0.4583 - val_loss: 3.9901 - val_accuracy: 0.1111\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.6178 - accuracy: 0.4583 - val_loss: 4.0113 - val_accuracy: 0.1111\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6125 - accuracy: 0.4583 - val_loss: 4.0313 - val_accuracy: 0.1111\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6066 - accuracy: 0.4583 - val_loss: 4.0481 - val_accuracy: 0.1111\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.6011 - accuracy: 0.4583 - val_loss: 4.0657 - val_accuracy: 0.1111\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5958 - accuracy: 0.4583 - val_loss: 4.0832 - val_accuracy: 0.1111\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.5900 - accuracy: 0.4583 - val_loss: 4.1018 - val_accuracy: 0.1111\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5845 - accuracy: 0.4583 - val_loss: 4.1229 - val_accuracy: 0.1111\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5798 - accuracy: 0.4583 - val_loss: 4.1453 - val_accuracy: 0.1111\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5729 - accuracy: 0.4583 - val_loss: 4.1676 - val_accuracy: 0.1111\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5668 - accuracy: 0.4583 - val_loss: 4.1903 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.5603 - accuracy: 0.4583 - val_loss: 4.2110 - val_accuracy: 0.1111\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5555 - accuracy: 0.4583 - val_loss: 4.2300 - val_accuracy: 0.1111\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5503 - accuracy: 0.4583 - val_loss: 4.2510 - val_accuracy: 0.1111\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5432 - accuracy: 0.4583 - val_loss: 4.2699 - val_accuracy: 0.1111\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5364 - accuracy: 0.4583 - val_loss: 4.2874 - val_accuracy: 0.1111\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5304 - accuracy: 0.4583 - val_loss: 4.3055 - val_accuracy: 0.1111\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5242 - accuracy: 0.4583 - val_loss: 4.3265 - val_accuracy: 0.1111\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5169 - accuracy: 0.4583 - val_loss: 4.3507 - val_accuracy: 0.1111\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5106 - accuracy: 0.4583 - val_loss: 4.3777 - val_accuracy: 0.1111\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.5042 - accuracy: 0.4583 - val_loss: 4.4018 - val_accuracy: 0.1111\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.4971 - accuracy: 0.4583 - val_loss: 4.4233 - val_accuracy: 0.1111\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4900 - accuracy: 0.4583 - val_loss: 4.4430 - val_accuracy: 0.1111\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4832 - accuracy: 0.4583 - val_loss: 4.4628 - val_accuracy: 0.1111\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.4758 - accuracy: 0.4583 - val_loss: 4.4815 - val_accuracy: 0.1111\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4688 - accuracy: 0.4583 - val_loss: 4.5022 - val_accuracy: 0.1111\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4622 - accuracy: 0.4583 - val_loss: 4.5227 - val_accuracy: 0.1111\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.4543 - accuracy: 0.4583 - val_loss: 4.5455 - val_accuracy: 0.1111\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4470 - accuracy: 0.4583 - val_loss: 4.5691 - val_accuracy: 0.1111\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4400 - accuracy: 0.4583 - val_loss: 4.5946 - val_accuracy: 0.1111\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4316 - accuracy: 0.4583 - val_loss: 4.6185 - val_accuracy: 0.1111\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.4236 - accuracy: 0.4583 - val_loss: 4.6393 - val_accuracy: 0.1111\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4163 - accuracy: 0.4583 - val_loss: 4.6627 - val_accuracy: 0.1111\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.4078 - accuracy: 0.4583 - val_loss: 4.6833 - val_accuracy: 0.1111\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4005 - accuracy: 0.4583 - val_loss: 4.7015 - val_accuracy: 0.1111\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3924 - accuracy: 0.4583 - val_loss: 4.7195 - val_accuracy: 0.1111\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3853 - accuracy: 0.5000 - val_loss: 4.7374 - val_accuracy: 0.1111\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3763 - accuracy: 0.5000 - val_loss: 4.7618 - val_accuracy: 0.1111\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3672 - accuracy: 0.5000 - val_loss: 4.7909 - val_accuracy: 0.1111\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3602 - accuracy: 0.4583 - val_loss: 4.8254 - val_accuracy: 0.1111\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3495 - accuracy: 0.4583 - val_loss: 4.8627 - val_accuracy: 0.1111\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3409 - accuracy: 0.4583 - val_loss: 4.8999 - val_accuracy: 0.1111\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3323 - accuracy: 0.4583 - val_loss: 4.9346 - val_accuracy: 0.1111\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3238 - accuracy: 0.4583 - val_loss: 4.9693 - val_accuracy: 0.1111\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3150 - accuracy: 0.4583 - val_loss: 4.9995 - val_accuracy: 0.1111\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3065 - accuracy: 0.4583 - val_loss: 5.0242 - val_accuracy: 0.1111\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2991 - accuracy: 0.4583 - val_loss: 5.0482 - val_accuracy: 0.1111\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2897 - accuracy: 0.4583 - val_loss: 5.0742 - val_accuracy: 0.1111\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2830 - accuracy: 0.5000 - val_loss: 5.0991 - val_accuracy: 0.1111\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2744 - accuracy: 0.5000 - val_loss: 5.1198 - val_accuracy: 0.1111\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2660 - accuracy: 0.5000 - val_loss: 5.1432 - val_accuracy: 0.1111\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2566 - accuracy: 0.5417 - val_loss: 5.1712 - val_accuracy: 0.1111\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2483 - accuracy: 0.6250 - val_loss: 5.1990 - val_accuracy: 0.1111\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2386 - accuracy: 0.6667 - val_loss: 5.2357 - val_accuracy: 0.1111\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2302 - accuracy: 0.6250 - val_loss: 5.2752 - val_accuracy: 0.1111\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2214 - accuracy: 0.6667 - val_loss: 5.3144 - val_accuracy: 0.1111\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2134 - accuracy: 0.6667 - val_loss: 5.3524 - val_accuracy: 0.1111\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2043 - accuracy: 0.6667 - val_loss: 5.3859 - val_accuracy: 0.1111\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1960 - accuracy: 0.6667 - val_loss: 5.4169 - val_accuracy: 0.1111\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1880 - accuracy: 0.6667 - val_loss: 5.4468 - val_accuracy: 0.1111\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1803 - accuracy: 0.6667 - val_loss: 5.4782 - val_accuracy: 0.1111\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1719 - accuracy: 0.6667 - val_loss: 5.5128 - val_accuracy: 0.1111\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1635 - accuracy: 0.6667 - val_loss: 5.5445 - val_accuracy: 0.1111\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1556 - accuracy: 0.6667 - val_loss: 5.5740 - val_accuracy: 0.1111\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1471 - accuracy: 0.6667 - val_loss: 5.6043 - val_accuracy: 0.1111\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1391 - accuracy: 0.6667 - val_loss: 5.6375 - val_accuracy: 0.1111\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1316 - accuracy: 0.6667 - val_loss: 5.6707 - val_accuracy: 0.1111\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1247 - accuracy: 0.6667 - val_loss: 5.7038 - val_accuracy: 0.1111\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1160 - accuracy: 0.6667 - val_loss: 5.7303 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1082 - accuracy: 0.6667 - val_loss: 5.7564 - val_accuracy: 0.1111\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1007 - accuracy: 0.6667 - val_loss: 5.7867 - val_accuracy: 0.1111\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0932 - accuracy: 0.6667 - val_loss: 5.8254 - val_accuracy: 0.1111\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0850 - accuracy: 0.7083 - val_loss: 5.8627 - val_accuracy: 0.1111\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0778 - accuracy: 0.7083 - val_loss: 5.9039 - val_accuracy: 0.1111\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0700 - accuracy: 0.7083 - val_loss: 5.9441 - val_accuracy: 0.1111\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0623 - accuracy: 0.7083 - val_loss: 5.9871 - val_accuracy: 0.1111\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0544 - accuracy: 0.7083 - val_loss: 6.0276 - val_accuracy: 0.1111\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0473 - accuracy: 0.6667 - val_loss: 6.0661 - val_accuracy: 0.1111\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0428 - accuracy: 0.6667 - val_loss: 6.1033 - val_accuracy: 0.1111\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0347 - accuracy: 0.6667 - val_loss: 6.1337 - val_accuracy: 0.1111\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0269 - accuracy: 0.6667 - val_loss: 6.1612 - val_accuracy: 0.1111\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0190 - accuracy: 0.6667 - val_loss: 6.1830 - val_accuracy: 0.1111\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0126 - accuracy: 0.6667 - val_loss: 6.2058 - val_accuracy: 0.1111\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0049 - accuracy: 0.7083 - val_loss: 6.2384 - val_accuracy: 0.1111\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9976 - accuracy: 0.7083 - val_loss: 6.2809 - val_accuracy: 0.1111\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9903 - accuracy: 0.7083 - val_loss: 6.3257 - val_accuracy: 0.1111\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9836 - accuracy: 0.7083 - val_loss: 6.3685 - val_accuracy: 0.1111\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.9779 - accuracy: 0.6667 - val_loss: 6.4071 - val_accuracy: 0.1111\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9714 - accuracy: 0.7083 - val_loss: 6.4361 - val_accuracy: 0.1111\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9638 - accuracy: 0.7083 - val_loss: 6.4640 - val_accuracy: 0.1111\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9578 - accuracy: 0.7083 - val_loss: 6.4932 - val_accuracy: 0.1111\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9513 - accuracy: 0.7083 - val_loss: 6.5097 - val_accuracy: 0.1111\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9431 - accuracy: 0.7083 - val_loss: 6.5333 - val_accuracy: 0.1111\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9372 - accuracy: 0.7083 - val_loss: 6.5597 - val_accuracy: 0.1111\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9299 - accuracy: 0.7083 - val_loss: 6.5873 - val_accuracy: 0.1111\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9247 - accuracy: 0.7083 - val_loss: 6.6203 - val_accuracy: 0.1111\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9188 - accuracy: 0.7083 - val_loss: 6.6542 - val_accuracy: 0.1111\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9131 - accuracy: 0.7083 - val_loss: 6.6942 - val_accuracy: 0.1111\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9069 - accuracy: 0.7083 - val_loss: 6.7380 - val_accuracy: 0.1111\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9002 - accuracy: 0.7083 - val_loss: 6.7719 - val_accuracy: 0.1111\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8934 - accuracy: 0.7500 - val_loss: 6.8020 - val_accuracy: 0.1111\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8861 - accuracy: 0.7500 - val_loss: 6.8374 - val_accuracy: 0.1111\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8801 - accuracy: 0.7500 - val_loss: 6.8765 - val_accuracy: 0.1111\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8757 - accuracy: 0.7500 - val_loss: 6.9158 - val_accuracy: 0.1111\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8689 - accuracy: 0.7500 - val_loss: 6.9524 - val_accuracy: 0.1111\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8629 - accuracy: 0.7500 - val_loss: 6.9930 - val_accuracy: 0.1111\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8566 - accuracy: 0.7500 - val_loss: 7.0201 - val_accuracy: 0.1111\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8502 - accuracy: 0.7500 - val_loss: 7.0382 - val_accuracy: 0.1111\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8441 - accuracy: 0.7500 - val_loss: 7.0606 - val_accuracy: 0.1111\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8379 - accuracy: 0.7917 - val_loss: 7.0837 - val_accuracy: 0.1111\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8320 - accuracy: 0.7917 - val_loss: 7.1153 - val_accuracy: 0.1111\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8251 - accuracy: 0.7917 - val_loss: 7.1577 - val_accuracy: 0.1111\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8205 - accuracy: 0.7917 - val_loss: 7.2054 - val_accuracy: 0.1111\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8135 - accuracy: 0.7917 - val_loss: 7.2394 - val_accuracy: 0.1111\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8073 - accuracy: 0.7917 - val_loss: 7.2728 - val_accuracy: 0.1111\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8020 - accuracy: 0.7917 - val_loss: 7.3074 - val_accuracy: 0.1111\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7954 - accuracy: 0.7917 - val_loss: 7.3430 - val_accuracy: 0.1111\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7885 - accuracy: 0.7917 - val_loss: 7.3780 - val_accuracy: 0.1111\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7830 - accuracy: 0.7917 - val_loss: 7.4122 - val_accuracy: 0.1111\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7768 - accuracy: 0.7917 - val_loss: 7.4473 - val_accuracy: 0.1111\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7717 - accuracy: 0.7917 - val_loss: 7.4856 - val_accuracy: 0.1111\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7654 - accuracy: 0.7917 - val_loss: 7.5135 - val_accuracy: 0.1111\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7596 - accuracy: 0.7917 - val_loss: 7.5454 - val_accuracy: 0.1111\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7543 - accuracy: 0.7917 - val_loss: 7.5841 - val_accuracy: 0.1111\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7480 - accuracy: 0.7917 - val_loss: 7.6303 - val_accuracy: 0.1111\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7428 - accuracy: 0.7917 - val_loss: 7.6706 - val_accuracy: 0.1111\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7385 - accuracy: 0.7917 - val_loss: 7.7067 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7324 - accuracy: 0.8333 - val_loss: 7.7419 - val_accuracy: 0.1111\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7268 - accuracy: 0.8333 - val_loss: 7.7776 - val_accuracy: 0.1111\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7209 - accuracy: 0.8333 - val_loss: 7.7980 - val_accuracy: 0.1111\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7146 - accuracy: 0.8333 - val_loss: 7.8103 - val_accuracy: 0.1111\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7114 - accuracy: 0.8750 - val_loss: 7.8263 - val_accuracy: 0.1111\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7058 - accuracy: 0.8333 - val_loss: 7.8625 - val_accuracy: 0.1111\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7006 - accuracy: 0.8750 - val_loss: 7.9198 - val_accuracy: 0.1111\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6930 - accuracy: 0.8750 - val_loss: 7.9797 - val_accuracy: 0.1111\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6873 - accuracy: 0.8750 - val_loss: 8.0400 - val_accuracy: 0.1111\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6819 - accuracy: 0.8750 - val_loss: 8.0965 - val_accuracy: 0.1111\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6766 - accuracy: 0.8750 - val_loss: 8.1547 - val_accuracy: 0.1111\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6717 - accuracy: 0.8750 - val_loss: 8.1951 - val_accuracy: 0.1111\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6659 - accuracy: 0.8750 - val_loss: 8.2141 - val_accuracy: 0.1111\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6606 - accuracy: 0.8333 - val_loss: 8.2230 - val_accuracy: 0.1111\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6550 - accuracy: 0.8333 - val_loss: 8.2295 - val_accuracy: 0.1111\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6498 - accuracy: 0.8333 - val_loss: 8.2500 - val_accuracy: 0.1111\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6455 - accuracy: 0.8333 - val_loss: 8.2825 - val_accuracy: 0.1111\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6398 - accuracy: 0.8333 - val_loss: 8.3273 - val_accuracy: 0.1111\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6334 - accuracy: 0.8333 - val_loss: 8.3852 - val_accuracy: 0.1111\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6283 - accuracy: 0.8333 - val_loss: 8.4473 - val_accuracy: 0.1111\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6234 - accuracy: 0.8750 - val_loss: 8.5072 - val_accuracy: 0.1111\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6197 - accuracy: 0.8750 - val_loss: 8.5677 - val_accuracy: 0.1111\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6160 - accuracy: 0.8750 - val_loss: 8.6119 - val_accuracy: 0.1111\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6102 - accuracy: 0.8750 - val_loss: 8.6263 - val_accuracy: 0.1111\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6045 - accuracy: 0.8750 - val_loss: 8.6347 - val_accuracy: 0.1111\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5972 - accuracy: 0.8750 - val_loss: 8.6544 - val_accuracy: 0.1111\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5932 - accuracy: 0.8750 - val_loss: 8.6767 - val_accuracy: 0.1111\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5875 - accuracy: 0.8750 - val_loss: 8.7188 - val_accuracy: 0.1111\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5817 - accuracy: 0.8750 - val_loss: 8.7629 - val_accuracy: 0.1111\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5765 - accuracy: 0.8750 - val_loss: 8.8011 - val_accuracy: 0.1111\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5730 - accuracy: 0.8750 - val_loss: 8.8386 - val_accuracy: 0.1111\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5665 - accuracy: 0.8750 - val_loss: 8.8817 - val_accuracy: 0.1111\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5611 - accuracy: 0.8750 - val_loss: 8.9222 - val_accuracy: 0.1111\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5568 - accuracy: 0.8750 - val_loss: 8.9637 - val_accuracy: 0.1111\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5519 - accuracy: 0.8750 - val_loss: 8.9976 - val_accuracy: 0.1111\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5464 - accuracy: 0.8750 - val_loss: 9.0154 - val_accuracy: 0.1111\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5406 - accuracy: 0.8750 - val_loss: 9.0377 - val_accuracy: 0.1111\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5353 - accuracy: 0.8750 - val_loss: 9.0719 - val_accuracy: 0.1111\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5306 - accuracy: 0.8750 - val_loss: 9.1141 - val_accuracy: 0.1111\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5254 - accuracy: 0.9583 - val_loss: 9.1672 - val_accuracy: 0.1111\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5203 - accuracy: 0.9583 - val_loss: 9.2304 - val_accuracy: 0.1111\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5157 - accuracy: 0.8750 - val_loss: 9.2953 - val_accuracy: 0.1111\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5100 - accuracy: 0.8750 - val_loss: 9.3339 - val_accuracy: 0.1111\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5055 - accuracy: 0.9167 - val_loss: 9.3612 - val_accuracy: 0.1111\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4994 - accuracy: 0.9583 - val_loss: 9.3922 - val_accuracy: 0.1111\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4944 - accuracy: 0.9583 - val_loss: 9.4182 - val_accuracy: 0.1111\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4904 - accuracy: 0.9583 - val_loss: 9.4440 - val_accuracy: 0.1111\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4852 - accuracy: 0.9583 - val_loss: 9.4774 - val_accuracy: 0.1111\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4792 - accuracy: 0.9583 - val_loss: 9.5260 - val_accuracy: 0.1111\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4744 - accuracy: 0.9583 - val_loss: 9.5892 - val_accuracy: 0.1111\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4697 - accuracy: 0.9583 - val_loss: 9.6438 - val_accuracy: 0.1111\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4649 - accuracy: 0.9583 - val_loss: 9.7036 - val_accuracy: 0.1111\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4633 - accuracy: 0.9583 - val_loss: 9.7572 - val_accuracy: 0.1111\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4558 - accuracy: 0.9583 - val_loss: 9.7622 - val_accuracy: 0.1111\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4518 - accuracy: 0.9583 - val_loss: 9.7631 - val_accuracy: 0.1111\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4459 - accuracy: 0.9583 - val_loss: 9.7900 - val_accuracy: 0.1111\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4408 - accuracy: 0.9583 - val_loss: 9.8338 - val_accuracy: 0.1111\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4360 - accuracy: 0.9583 - val_loss: 9.8813 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4310 - accuracy: 0.9583 - val_loss: 9.9336 - val_accuracy: 0.1111\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4268 - accuracy: 0.9583 - val_loss: 9.9936 - val_accuracy: 0.1111\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4216 - accuracy: 0.9583 - val_loss: 10.0462 - val_accuracy: 0.1111\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4170 - accuracy: 0.9583 - val_loss: 10.0907 - val_accuracy: 0.1111\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4129 - accuracy: 0.9583 - val_loss: 10.1196 - val_accuracy: 0.1111\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4071 - accuracy: 0.9583 - val_loss: 10.1523 - val_accuracy: 0.1111\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4027 - accuracy: 0.9583 - val_loss: 10.1951 - val_accuracy: 0.1111\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3988 - accuracy: 0.9583 - val_loss: 10.2390 - val_accuracy: 0.1111\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3946 - accuracy: 0.9583 - val_loss: 10.2764 - val_accuracy: 0.1111\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3901 - accuracy: 0.9583 - val_loss: 10.3048 - val_accuracy: 0.1111\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3841 - accuracy: 0.9583 - val_loss: 10.3232 - val_accuracy: 0.1111\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3796 - accuracy: 0.9583 - val_loss: 10.3493 - val_accuracy: 0.1111\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3754 - accuracy: 0.9583 - val_loss: 10.3869 - val_accuracy: 0.1111\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3719 - accuracy: 0.9583 - val_loss: 10.4267 - val_accuracy: 0.1111\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3678 - accuracy: 0.9583 - val_loss: 10.4747 - val_accuracy: 0.1111\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3637 - accuracy: 0.9583 - val_loss: 10.5386 - val_accuracy: 0.1111\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3584 - accuracy: 1.0000 - val_loss: 10.5851 - val_accuracy: 0.1111\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 10.6267 - val_accuracy: 0.1111\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3503 - accuracy: 1.0000 - val_loss: 10.6639 - val_accuracy: 0.1111\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3448 - accuracy: 1.0000 - val_loss: 10.6816 - val_accuracy: 0.1111\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3418 - accuracy: 1.0000 - val_loss: 10.7120 - val_accuracy: 0.1111\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3373 - accuracy: 1.0000 - val_loss: 10.7539 - val_accuracy: 0.1111\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 1.00 - 0s 34ms/step - loss: 0.3325 - accuracy: 1.0000 - val_loss: 10.8027 - val_accuracy: 0.1111\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3281 - accuracy: 1.0000 - val_loss: 10.8525 - val_accuracy: 0.1111\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3251 - accuracy: 1.0000 - val_loss: 10.8961 - val_accuracy: 0.1111\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3212 - accuracy: 1.0000 - val_loss: 10.9185 - val_accuracy: 0.1111\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3169 - accuracy: 1.0000 - val_loss: 10.9467 - val_accuracy: 0.1111\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3130 - accuracy: 1.0000 - val_loss: 10.9770 - val_accuracy: 0.1111\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3097 - accuracy: 1.0000 - val_loss: 11.0047 - val_accuracy: 0.1111\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3060 - accuracy: 1.0000 - val_loss: 11.0478 - val_accuracy: 0.1111\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3017 - accuracy: 1.0000 - val_loss: 11.0956 - val_accuracy: 0.1111\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2984 - accuracy: 1.0000 - val_loss: 11.1494 - val_accuracy: 0.1111\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 11.1959 - val_accuracy: 0.1111\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 11.2348 - val_accuracy: 0.1111\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 11.2681 - val_accuracy: 0.1111\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 11.2988 - val_accuracy: 0.1111\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 11.3351 - val_accuracy: 0.1111\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 11.3826 - val_accuracy: 0.1111\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2728 - accuracy: 1.0000 - val_loss: 11.4203 - val_accuracy: 0.1111\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 11.4613 - val_accuracy: 0.1111\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2653 - accuracy: 1.0000 - val_loss: 11.5109 - val_accuracy: 0.1111\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 11.5703 - val_accuracy: 0.1111\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2597 - accuracy: 1.0000 - val_loss: 11.6146 - val_accuracy: 0.1111\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2562 - accuracy: 1.0000 - val_loss: 11.6356 - val_accuracy: 0.1111\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 11.6431 - val_accuracy: 0.1111\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 11.6504 - val_accuracy: 0.1111\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 11.6832 - val_accuracy: 0.1111\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2439 - accuracy: 1.0000 - val_loss: 11.7379 - val_accuracy: 0.1111\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2402 - accuracy: 1.0000 - val_loss: 11.7977 - val_accuracy: 0.1111\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2369 - accuracy: 1.0000 - val_loss: 11.8495 - val_accuracy: 0.1111\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2343 - accuracy: 1.0000 - val_loss: 11.8952 - val_accuracy: 0.1111\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 11.9278 - val_accuracy: 0.1111\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2289 - accuracy: 1.0000 - val_loss: 11.9464 - val_accuracy: 0.1111\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2260 - accuracy: 1.0000 - val_loss: 11.9616 - val_accuracy: 0.1111\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2229 - accuracy: 1.0000 - val_loss: 11.9941 - val_accuracy: 0.1111\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2197 - accuracy: 1.0000 - val_loss: 12.0415 - val_accuracy: 0.1111\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 12.1007 - val_accuracy: 0.1111\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2147 - accuracy: 1.0000 - val_loss: 12.1567 - val_accuracy: 0.1111\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2119 - accuracy: 1.0000 - val_loss: 12.1929 - val_accuracy: 0.1111\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2098 - accuracy: 1.0000 - val_loss: 12.2172 - val_accuracy: 0.1111\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2066 - accuracy: 1.0000 - val_loss: 12.2430 - val_accuracy: 0.1111\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2038 - accuracy: 1.0000 - val_loss: 12.2684 - val_accuracy: 0.1111\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2015 - accuracy: 1.0000 - val_loss: 12.2948 - val_accuracy: 0.1111\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1993 - accuracy: 1.0000 - val_loss: 12.3324 - val_accuracy: 0.1111\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 12.3848 - val_accuracy: 0.1111\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1938 - accuracy: 1.0000 - val_loss: 12.4369 - val_accuracy: 0.1111\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1922 - accuracy: 1.0000 - val_loss: 12.4750 - val_accuracy: 0.1111\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 12.4982 - val_accuracy: 0.1111\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 12.5153 - val_accuracy: 0.1111\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 12.5385 - val_accuracy: 0.1111\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1825 - accuracy: 1.0000 - val_loss: 12.5693 - val_accuracy: 0.1111\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 12.6062 - val_accuracy: 0.1111\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1782 - accuracy: 1.0000 - val_loss: 12.6522 - val_accuracy: 0.1111\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1755 - accuracy: 1.0000 - val_loss: 12.7052 - val_accuracy: 0.1111\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 12.7533 - val_accuracy: 0.1111\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 12.7886 - val_accuracy: 0.1111\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 12.8020 - val_accuracy: 0.1111\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 12.8081 - val_accuracy: 0.1111\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 12.8305 - val_accuracy: 0.1111\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1632 - accuracy: 1.0000 - val_loss: 12.8682 - val_accuracy: 0.1111\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1615 - accuracy: 1.0000 - val_loss: 12.9125 - val_accuracy: 0.1111\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1592 - accuracy: 1.0000 - val_loss: 12.9665 - val_accuracy: 0.1111\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1576 - accuracy: 1.0000 - val_loss: 13.0145 - val_accuracy: 0.1111\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 13.0395 - val_accuracy: 0.1111\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1539 - accuracy: 1.0000 - val_loss: 13.0519 - val_accuracy: 0.1111\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 13.0555 - val_accuracy: 0.1111\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1502 - accuracy: 1.0000 - val_loss: 13.0655 - val_accuracy: 0.1111\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1488 - accuracy: 1.0000 - val_loss: 13.0957 - val_accuracy: 0.1111\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1469 - accuracy: 1.0000 - val_loss: 13.1423 - val_accuracy: 0.1111\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 13.1984 - val_accuracy: 0.1111\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1432 - accuracy: 1.0000 - val_loss: 13.2476 - val_accuracy: 0.1111\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1416 - accuracy: 1.0000 - val_loss: 13.2882 - val_accuracy: 0.1111\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 13.3111 - val_accuracy: 0.1111\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 13.3278 - val_accuracy: 0.1111\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 13.3502 - val_accuracy: 0.1111\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 13.3780 - val_accuracy: 0.1111\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1335 - accuracy: 1.0000 - val_loss: 13.4095 - val_accuracy: 0.1111\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 13.4468 - val_accuracy: 0.1111\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 13.4675 - val_accuracy: 0.1111\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 13.4954 - val_accuracy: 0.1111\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 13.5148 - val_accuracy: 0.1111\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 13.5457 - val_accuracy: 0.1111\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 13.5880 - val_accuracy: 0.1111\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 13.6230 - val_accuracy: 0.1111\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1215 - accuracy: 1.0000 - val_loss: 13.6439 - val_accuracy: 0.1111\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1203 - accuracy: 1.0000 - val_loss: 13.6775 - val_accuracy: 0.1111\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 13.7177 - val_accuracy: 0.1111\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1177 - accuracy: 1.0000 - val_loss: 13.7609 - val_accuracy: 0.1111\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 13.7947 - val_accuracy: 0.1111\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 13.8265 - val_accuracy: 0.1111\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 13.8505 - val_accuracy: 0.1111\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1124 - accuracy: 1.0000 - val_loss: 13.8673 - val_accuracy: 0.1111\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 13.8893 - val_accuracy: 0.1111\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 13.9171 - val_accuracy: 0.1111\n",
      "Epoch 403/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 13.9525 - val_accuracy: 0.1111\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 13.9790 - val_accuracy: 0.1111\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 14.0039 - val_accuracy: 0.1111\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 14.0182 - val_accuracy: 0.1111\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 14.0411 - val_accuracy: 0.1111\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 14.0695 - val_accuracy: 0.1111\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 14.0959 - val_accuracy: 0.1111\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 14.1332 - val_accuracy: 0.1111\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 14.1642 - val_accuracy: 0.1111\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 14.1810 - val_accuracy: 0.1111\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 14.1939 - val_accuracy: 0.1111\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 14.2125 - val_accuracy: 0.1111\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 14.2259 - val_accuracy: 0.1111\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 14.2595 - val_accuracy: 0.1111\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 14.2929 - val_accuracy: 0.1111\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 14.3318 - val_accuracy: 0.1111\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 14.3582 - val_accuracy: 0.1111\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 14.3823 - val_accuracy: 0.1111\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 14.4080 - val_accuracy: 0.1111\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 14.4351 - val_accuracy: 0.1111\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 14.4563 - val_accuracy: 0.1111\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 14.4808 - val_accuracy: 0.1111\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 14.4941 - val_accuracy: 0.1111\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 14.5168 - val_accuracy: 0.1111\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 14.5447 - val_accuracy: 0.1111\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 14.5739 - val_accuracy: 0.1111\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0825 - accuracy: 1.0000 - val_loss: 14.6026 - val_accuracy: 0.1111\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 14.6370 - val_accuracy: 0.1111\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 14.6777 - val_accuracy: 0.1111\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 14.7143 - val_accuracy: 0.1111\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 14.7446 - val_accuracy: 0.1111\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 14.7711 - val_accuracy: 0.1111\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 14.7933 - val_accuracy: 0.1111\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 14.8064 - val_accuracy: 0.1111\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 14.8275 - val_accuracy: 0.1111\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 14.8506 - val_accuracy: 0.1111\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 14.8673 - val_accuracy: 0.1111\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 14.8877 - val_accuracy: 0.1111\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 14.9045 - val_accuracy: 0.1111\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 14.9214 - val_accuracy: 0.1111\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 14.9449 - val_accuracy: 0.1111\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 14.9734 - val_accuracy: 0.1111\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 14.9979 - val_accuracy: 0.1111\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 15.0181 - val_accuracy: 0.1111\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 15.0290 - val_accuracy: 0.1111\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 15.0450 - val_accuracy: 0.1111\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 15.0637 - val_accuracy: 0.1111\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 15.0831 - val_accuracy: 0.1111\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 15.1012 - val_accuracy: 0.1111\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 15.1232 - val_accuracy: 0.1111\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 15.1449 - val_accuracy: 0.1111\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 15.1647 - val_accuracy: 0.1111\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 15.1796 - val_accuracy: 0.1111\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 15.2035 - val_accuracy: 0.1111\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 15.2299 - val_accuracy: 0.1111\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 15.2512 - val_accuracy: 0.1111\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 15.2756 - val_accuracy: 0.1111\n",
      "Epoch 460/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 15.2979 - val_accuracy: 0.1111\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 15.3156 - val_accuracy: 0.1111\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 15.3396 - val_accuracy: 0.1111\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 15.3573 - val_accuracy: 0.1111\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 15.3663 - val_accuracy: 0.1111\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 15.3807 - val_accuracy: 0.1111\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 15.3967 - val_accuracy: 0.1111\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 15.4122 - val_accuracy: 0.1111\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 15.4329 - val_accuracy: 0.1111\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 15.4632 - val_accuracy: 0.1111\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 15.4922 - val_accuracy: 0.1111\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 15.5234 - val_accuracy: 0.1111\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 15.5454 - val_accuracy: 0.1111\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 15.5574 - val_accuracy: 0.1111\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 15.5667 - val_accuracy: 0.1111\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 15.5771 - val_accuracy: 0.1111\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 15.5952 - val_accuracy: 0.1111\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 15.6203 - val_accuracy: 0.1111\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 15.6424 - val_accuracy: 0.1111\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 15.6583 - val_accuracy: 0.1111\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 15.6814 - val_accuracy: 0.1111\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 15.7017 - val_accuracy: 0.1111\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 15.7160 - val_accuracy: 0.1111\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 15.7318 - val_accuracy: 0.1111\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 15.7586 - val_accuracy: 0.1111\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 15.7781 - val_accuracy: 0.1111\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 15.7984 - val_accuracy: 0.1111\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 15.8175 - val_accuracy: 0.1111\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 15.8291 - val_accuracy: 0.1111\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 15.8352 - val_accuracy: 0.1111\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 15.8434 - val_accuracy: 0.1111\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 15.8558 - val_accuracy: 0.1111\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 15.8723 - val_accuracy: 0.1111\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 15.8923 - val_accuracy: 0.1111\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 15.9123 - val_accuracy: 0.1111\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 15.9389 - val_accuracy: 0.1111\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 15.9591 - val_accuracy: 0.1111\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 15.9782 - val_accuracy: 0.1111\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 15.9972 - val_accuracy: 0.1111\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 16.0168 - val_accuracy: 0.1111\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 16.0401 - val_accuracy: 0.1111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epochs = 500\n",
    "# history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n",
    "#  train our model\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels),  validation_split=0.25, epochs=epochs, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "balanced-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 500, 'steps': 2}\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "Final training loss \t 0.04288799688220024\n",
      "Final training accuracy  1.0\n"
     ]
    }
   ],
   "source": [
    "# Explore History details\n",
    "print(history.params)\n",
    "print(history.history.keys())\n",
    "print('Final training loss \\t', history.history['loss'][-1])\n",
    "print('Final training accuracy ',history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-sector",
   "metadata": {},
   "source": [
    "### Pickle can be used to serialize Python object structures, which refers to the process of converting an object in the memory to a byte stream that can be stored as a binary file on disk. When we load it back to a Python program, this binary file can be de-serialized back to a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "whole-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'sparse_categorical_crossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e169492e51db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m212\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SparseC Categorical Crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m# pyplot.plot(history.history['val_sparse_categorical_crossentropy'], label='test')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sparse_categorical_crossentropy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'test'], loc='upper left')\n",
    "pyplot.savefig('intent_accuracy.png')\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'test'], loc='upper left')\n",
    "pyplot.savefig('intent_loss.png')\n",
    "pyplot.show()\n",
    "\n",
    "# plot mse during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('SparseC Categorical Crossentropy')\n",
    "pyplot.plot(history.history['sparse_categorical_crossentropy'], label='train')\n",
    "# pyplot.plot(history.history['val_sparse_categorical_crossentropy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.savefig('intent_mse.png')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intent.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "        print (lbl_encoder)\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        #print(CLASSES[np.argmax(result)])\n",
    "        print([np.argmax(result)])\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "        print(\"****************\")\n",
    "        print(tag)\n",
    "#         print(data['intents'])\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
