{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk==3.5\n",
    "# !pip install colorama==0.4.3\n",
    "# !pip install numpy==1.18.5\n",
    "# !pip install scikit_learn==0.23.2\n",
    "# !pip install Flask==1.1.2\n",
    "#https://towardsdatascience.com/how-to-build-your-own-chatbot-using-deep-learning-bb41f970e281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "touched-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-encyclopedia",
   "metadata": {},
   "source": [
    "### Loading Json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "harmful-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intent.json') as file:\n",
    " data=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "distributed-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'goodbye',\n",
       " 'thanks',\n",
       " 'about',\n",
       " 'name',\n",
       " 'help',\n",
       " 'createaccount',\n",
       " 'complaint']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentences=[]\n",
    "training_labels=[]\n",
    "labels=[]\n",
    "responses=[]\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])     \n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "        \n",
    "num_classes=len(labels)        \n",
    "    \n",
    "    \n",
    "training_sentences   \n",
    "responses\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "applied-premiere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 3 3 3 7 7 7 7 0 0 0 6 6 6 5 5 5 5 5 5 5 2 2 2 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "lbl_encoder=LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels=lbl_encoder.transform(training_labels)\n",
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "initial-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "found-compensation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 16)            16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 16,680\n",
      "Trainable params: 16,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/#:~:text=The%20output%20of%20the%20Embedding,vector%20using%20the%20Flatten%20layer.\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "sensitive-mortality",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - ETA: 1s - loss: 0.0470 - accuracy: 1.00 - ETA: 0s - loss: 0.0520 - accuracy: 1.00 - 3s 2s/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 1.00 - 0s 213ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 1.00 - 0s 177ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 1.00 - 0s 92ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.00 - 0s 100ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 1.00 - 0s 136ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 1.00 - 0s 160ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 88ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.00 - 0s 68ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 1.00 - 0s 66ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.00 - 0s 64ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 1.00 - 0s 80ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 31ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 1.00 - 0s 27ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 1.00 - 0s 99ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 1.00 - 0s 136ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 1.00 - 0s 73ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 30ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.00 - 0s 29ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 1.00 - 0s 28ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.00 - 0s 59ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.00 - 0s 31ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 1.00 - 0s 30ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.00 - 0s 54ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.00 - 0s 29ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.00 - 0s 53ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.00 - 0s 85ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 49ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.00 - 0s 65ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 57ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 1.00 - 0s 51ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 26ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 53ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 52ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 50ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 53ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.8889\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.8889\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.8889\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.8889\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.8889\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.8889\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.8889\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.8889\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.8889\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.8889\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.8889\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.8889\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.8889\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.8889\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.8889\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.8889\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.8889\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.8889\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 55ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.8889\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 50ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.8889\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.8889\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8889\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.8889\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.8889\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8889\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.8889\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.8889\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.8889\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.8889\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.8889\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.8889\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.8889\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.8889\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.8889\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.8889\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.8889\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.8889\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.8889\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.8889\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.8889\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.8889\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.8889\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.8889\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.8889\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.8889\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.8889\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.8889\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.8889\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.8889\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.8889\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.8889\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.8889\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.8889\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.8889\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.8889\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - ETA: 0s - loss: 0.0092 - accuracy: 1.00 - 0s 127ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.8889\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.8889\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.8889\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 50ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.8889\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 50ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.8889\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.8889\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.8889\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.8889\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.8889\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.8889\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.8889\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.8889\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.8889\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.8889\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.8889\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.8889\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 31ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.8889\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 27ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.8889\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 31ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.8889\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 25ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.8889\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 26ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.8889\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 26ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.8889\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 27ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.8889\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 27ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.8889\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 27ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.8889\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.8889\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.8889\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 51ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.8889\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.8889\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.8889\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.8889\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.8889\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.8889\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.8889\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.8889\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.8889\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 48ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.8889\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 50ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.8889\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 49ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.8889\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 53ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.8889\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 60ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.8889\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.8889\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.8889\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.00 - 0s 51ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.8889\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.8889\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.8889\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.8889\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.8889\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.8889\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.8889\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.8889\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.8889\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.8889\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.8889\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.8889\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.8889\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.8889\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.8889\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.8889\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 31ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.8889\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 0.8889\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.8889\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.8889\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 44ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.8889\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 45ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.8889\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 56ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.8889\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 49ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.8889\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.8889\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.8889\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.8889\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.8889\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 32ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.8889\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.8889\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.8889\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.8889\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.8889\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.8889\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.8889\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.8889\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.8889\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.8889\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.8889\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.8889\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.8889\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.8889\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.8889\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.8889\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.8889\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.8889\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.8889\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.8889\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.8889\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.8889\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 47ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.8889\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 43ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.8889\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.8889\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8889\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.8889\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.8889\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.8889\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.8889\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.8889\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.8889\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.8889\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.8889\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.8889\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.8889\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.8889\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.8889\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 46ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8889\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.8889\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.8889\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.8889\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 61ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.8889\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.8889\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.8889\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.8889\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.8889\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 33ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.8889\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.8889\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.8889\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.8889\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.8889\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 35ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.8889\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 37ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.8889\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.8889\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.8889\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.8889\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epochs = 500\n",
    "# history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n",
    "#  train our model\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels),  validation_split=0.25, epochs=epochs, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "arranged-economics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 500, 'steps': 2}\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "Final training loss \t 0.0062435888685286045\n",
      "Final training accuracy  1.0\n"
     ]
    }
   ],
   "source": [
    "# Explore History details\n",
    "print(history.params)\n",
    "print(history.history.keys())\n",
    "print('Final training loss \\t', history.history['loss'][-1])\n",
    "print('Final training accuracy ',history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-melissa",
   "metadata": {},
   "source": [
    "### Pickle can be used to serialize Python object structures, which refers to the process of converting an object in the memory to a byte stream that can be stored as a binary file on disk. When we load it back to a Python program, this binary file can be de-serialized back to a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bigger-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'sparse_categorical_crossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-e169492e51db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m212\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SparseC Categorical Crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m# pyplot.plot(history.history['val_sparse_categorical_crossentropy'], label='test')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sparse_categorical_crossentropy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'test'], loc='upper left')\n",
    "pyplot.savefig('intent_accuracy.png')\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'test'], loc='upper left')\n",
    "pyplot.savefig('intent_loss.png')\n",
    "pyplot.show()\n",
    "\n",
    "# plot mse during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('SparseC Categorical Crossentropy')\n",
    "pyplot.plot(history.history['sparse_categorical_crossentropy'], label='train')\n",
    "# pyplot.plot(history.history['val_sparse_categorical_crossentropy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.savefig('intent_mse.png')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bronze-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: chat_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "LabelEncoder()\n",
      "User: hello\n",
      "[4]\n",
      "****************\n",
      "['greeting']\n",
      "ChatBot: Hi there\n",
      "User: "
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intent.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "        print (lbl_encoder)\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        #print(CLASSES[np.argmax(result)])\n",
    "        print([np.argmax(result)])\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "        print(\"****************\")\n",
    "        print(tag)\n",
    "#         print(data['intents'])\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
