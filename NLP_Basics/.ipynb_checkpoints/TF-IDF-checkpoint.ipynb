{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guided-jumping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geeks for geeks', 'Geeks', 'r2j']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/\n",
    "# https://www.kaggle.com/code/paulrohan2020/tf-idf-tutorial\n",
    "# import required module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# assign documents\n",
    "d0 = 'Geeks for geeks'\n",
    "d1 = 'Geeks'\n",
    "d2 = 'r2j'\n",
    " \n",
    "# merge documents into a single corpus\n",
    "string = [d0, d1, d2]\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-savage",
   "metadata": {},
   "source": [
    "TF stands for Term Frequency and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
    "\n",
    "   Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
    "\n",
    "Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "IDF stands for Inverse Document Frequency and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "   Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
    "\n",
    "In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
    "\n",
    "Finally:\n",
    "\n",
    "   TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unavailable-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    " \n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thrown-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "idf values:\n",
      "for : 1.6931471805599454\n",
      "geeks : 1.2876820724517808\n",
      "r2j : 1.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "# get idf values\n",
    "print('\\nidf values:')\n",
    "for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n",
    "    print(ele1, ':', ele2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exact-panama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'geeks': 1, 'for': 0, 'r2j': 2}\n",
      "\n",
      "tf-idf value:\n",
      "  (0, 0)\t0.5493512310263033\n",
      "  (0, 1)\t0.8355915419449176\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "\n",
      "tf-idf values in matrix form:\n",
      "[[0.54935123 0.83559154 0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# get indexing\n",
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)\n",
    " \n",
    "# display tf-idf values\n",
    "print('\\ntf-idf value:')\n",
    "print(result)\n",
    " \n",
    "# in matrix form\n",
    "print('\\ntf-idf values in matrix form:')\n",
    "print(result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "presidential-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'geek1': 0, 'geek2': 1, 'geek3': 2, 'geek4': 3}\n",
      "\n",
      "tf-idf values:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "# assign documents\n",
    "d0 = 'geek1'\n",
    "d1 = 'geek2'\n",
    "d2 = 'geek3'\n",
    "d3 = 'geek4'\n",
    " \n",
    "# merge documents into a single corpus\n",
    "string = [d0, d1, d2, d3]\n",
    " \n",
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    " \n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(string)\n",
    " \n",
    "# get indexing\n",
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)\n",
    " \n",
    "# display tf-idf values\n",
    "print('\\ntf-idf values:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regular-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'geeks': 1, 'for': 0}\n",
      "\n",
      "tf-idf values:\n",
      "  (0, 0)\t0.4472135954999579\n",
      "  (0, 1)\t0.8944271909999159\n",
      "  (1, 0)\t0.4472135954999579\n",
      "  (1, 1)\t0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# assign documents\n",
    "d0 = 'Geeks for geeks!'\n",
    "d1 = 'Geeks for geeks!'\n",
    "\n",
    "\n",
    "# merge documents into a single corpus\n",
    "string = [d0, d1]\n",
    "\n",
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(string)\n",
    "\n",
    "# get indexing\n",
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)\n",
    "\n",
    "# display tf-idf values\n",
    "print('\\ntf-idf values:')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'geeks': 0}\n",
      "\n",
      "tf-idf values:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# assign corpus\n",
    "string = ['Geeks geeks']*5\n",
    "\n",
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(string)\n",
    "\n",
    "# get indexing\n",
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)\n",
    "\n",
    "# display tf-idf values\n",
    "print('\\ntf-idf values:')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "after-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]\n",
    "#let's create the vectorizer and fit the corpus and transform them accordingly\n",
    "v = TfidfVectorizer()\n",
    "v.fit(corpus)\n",
    "transform_output = v.transform(corpus)\n",
    "#let's print the vocabulary\n",
    "\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "iraqi-slide",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2c66557822a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#let's print the idf of each word:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_feature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "#let's print the idf of each word:\n",
    "\n",
    "all_feature_names = v.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "    \n",
    "    #let's get the index in the vocabulary\n",
    "    indx = v.vocabulary_.get(word)\n",
    "    \n",
    "    #get the score\n",
    "    idf_score = v.idf_[indx]\n",
    "    \n",
    "    print(f\"{word} : {idf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
