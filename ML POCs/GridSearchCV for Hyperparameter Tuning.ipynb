{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latest-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 2, 3, 6], 'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Importing the libraries needed\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# Loading the Dataset\n",
    "# A standard dataset here is taken for better understanding.\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/pranavkotak8/Datasets/master/Iris.csv')\n",
    "target=iris['Species']\n",
    "iris.drop(columns={'Id','Species'},inplace=True)\n",
    " \n",
    "# Assigning the parameters and its values which need to be tuned.\n",
    "parameters = {'kernel': ['linear', 'rbf'], 'C':[1,2,3,6]}\n",
    " \n",
    "# Fitting the SVM model\n",
    "modelsvc = SVC()\n",
    " \n",
    "# Performing the GridSearchCV\n",
    "clf = GridSearchCV(modelsvc, parameters)\n",
    "clf.fit(iris, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diagnostic-debate",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10299, 150]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e3e2750eba5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Splitting into train and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m X_train,X_test,y_train,y_test=train_test_split(train_f,\n\u001b[1;32m---> 28\u001b[1;33m target, test_size = 0.8, random_state = 100)\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Importing the DaskGridSearchCV, importing time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\gpu2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10299, 150]"
     ]
    }
   ],
   "source": [
    "# Importing the libraries which are required:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading the train data\n",
    "train = pd.read_csv('C:\\\\Users\\\\navee\\\\JUPYTER NOTEBOOKS\\\\smartphone_activity_dataset.csv')\n",
    "\n",
    "# Dropping the target column\n",
    "train.drop(columns={'activity'},inplace=True)\n",
    "\n",
    "# Scaling the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "t = MinMaxScaler()\n",
    "train_f = t.fit_transform(train)\n",
    "train_f = pd.DataFrame(train_f)\n",
    "\n",
    "# Splitting into train and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_f,\n",
    "target, test_size = 0.8, random_state = 100)\n",
    "\n",
    "# Importing the DaskGridSearchCV, importing time\n",
    "# and also running the gridsearchcv\n",
    "# So here we are using DaskGridSearchCV.\n",
    "from dask_ml.model_selection import GridSearchCV as DaskGridSearchCV\n",
    "start=time.time()\n",
    "\n",
    "parameters={\n",
    "\t\t\t'C': [0.1, 1,5, 10,15,20,100,500],\n",
    "\t\t\t'gamma': [0.5,0.80,1, 0.1],\n",
    "\t\t\t'kernel': ['rbf','linear','sigmoid']}\n",
    "\t\n",
    "modelsvc=SVC()\n",
    "\n",
    "gscv = DaskGridSearchCV(modelsvc, param_grid = parameters, cv = 5, n_jobs = -1)\n",
    "\n",
    "grid_results = gscv.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Time Taken with Dask GridSearchCV:\", end-start)\n",
    "\n",
    "# Importing the GridSearchCV, importing time and\n",
    "# also running the gridsearchcv\n",
    "# So here we are using the normal GridSearchCV method to implement\n",
    "# the same algorithm and same parameters with the same set of values.\n",
    "# This is merely done to compare and measure the computational time for both the methods.\n",
    "start = time.time()\n",
    "gscv = GridSearchCV(svm.SVC(), {\n",
    "\t\t\t'C': [0.1, 1,5, 10,15,20,100,500],\n",
    "\t\t\t'gamma': [0.5,0.80,1, 0.1],\n",
    "\t\t\t'kernel': ['rbf','linear','sigmoid']\n",
    "},cv = 5,return_train_score = False,n_jobs = -1)\n",
    "\n",
    "grid_results = gscv.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Time Taken without Dask GridSearchCV:\", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
